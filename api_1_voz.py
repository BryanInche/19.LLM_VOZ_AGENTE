import speech_recognition as sr  #procesar voz y capturar lo que el usuario dice a trav√©s del micr√≥fono.
from langchain_community.llms import Ollama # Modelo LLM
from gtts import gTTS  # Para convertir respuesta de LLM en voz
import os  # Acceder a archivos del sistema
#from playsound import playsound  # Para reproducir audio sin dependencias externas
import pygame  # Para reproducir audio

from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate

import time
import psycopg2
import json
import psycopg2
import json
from datetime import datetime, timedelta

#pip install PyAudio
#pip install playsound
#pip install pygame

# Variable global para el tiempo de inicio de la conversaci√≥n
start_time = None

# Inicializar pygame para reproducir audio
pygame.mixer.init()

# üìå Configuraci√≥n de conexi√≥n a PostgreSQL
DB_CONFIG = {
    "dbname": "atom_db",
    "user": "atom",
    "password": "atom123",
    "host": "localhost",
    "port": "5433"
}

# Funci√≥n para capturar audio en tiempo real
def capturar_audio():
    # Objeto Recognizer para manejar la captura y transcripci√≥n de audio
    recognizer = sr.Recognizer()
    with sr.Microphone() as source: #Abre el micr√≥fono como fuente de audio
        print("Escuchando...")
        audio = recognizer.listen(source) #Capturamos el audio del micr√≥fono.
        try:
            #Transcribir el audio a texto en espa√±ol
            text = recognizer.recognize_google(audio, language="es-ES")
            print("Usuario:", text)
            return text  #texto transcrito
        except sr.UnknownValueError:
            print("No se pudo entender el audio")
        except sr.RequestError as e:
            print(f"Error al solicitar resultados: {e}")

# Funci√≥n para convertir texto a voz
#def texto_a_voz(texto, archivo_salida="respuesta.mp3"):
def texto_a_voz(texto):
    # Generar un nombre √∫nico para el archivo de audio
    archivo_salida = f"respuesta_{int(time.time())}.mp3"

    # Convertir texto a voz
    tts = gTTS(text=texto, lang="es") #objeto para convertir el texto en voz en espa√±ol
    tts.save(archivo_salida) #Guarda la voz generada en un archivo MP3
    print(f"Agente:", texto)


    # Reproducir el archivo de audio usando pygame
    pygame.mixer.music.load(archivo_salida)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():  # Esperar a que termine la reproducci√≥n
        pygame.time.Clock().tick(10)

    # Eliminar el archivo de audio despu√©s de reproducirlo
    #os.remove(archivo_salida)

def parse_respuesta(respuesta):
    """Parsea la respuesta del modelo LLM asegurando que sea un JSON v√°lido."""
    try:
        if isinstance(respuesta, str):  # Si es un string, intenta convertirlo en JSON
            respuesta = json.loads(respuesta.strip())
        
        if isinstance(respuesta, dict):  # Verifica estructura esperada
            return {
                "intencion": respuesta.get("intencion", ""),
                "nombre": respuesta.get("nombre"),
                "empresa": respuesta.get("empresa"),
                "necesidad": respuesta.get("necesidad"),
                "presupuesto": respuesta.get("presupuesto"),
                "respuesta": respuesta.get("respuesta", "No tengo informaci√≥n para responder.")
            }
        else:
            raise ValueError("La respuesta no es un diccionario v√°lido")
    
    except json.JSONDecodeError:
        print("‚ùå Error al convertir la respuesta en JSON:", respuesta)
        return {"respuesta": respuesta}  # Devolver un valor por defecto



def guardar_interaccion_bd(entrada_usuario, respuesta_parseada, duracion_interaccion=timedelta(seconds=15)):
    """Guarda la interacci√≥n en la base de datos PostgreSQL."""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        query = """
        INSERT INTO interacciones_voz (
            entrada_usuario, respuesta_agente, intencion, nombre_usuario, empresa, necesidad, 
            presupuesto, datos_json, duracion_interaccion, finalizada
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
        """
        
        values = (
            entrada_usuario,
            respuesta_parseada["respuesta"],
            respuesta_parseada["intencion"],
            respuesta_parseada["nombre"],
            respuesta_parseada["empresa"],
            respuesta_parseada["necesidad"],
            respuesta_parseada["presupuesto"],
            json.dumps(respuesta_parseada),
            duracion_interaccion,
            False  # La interacci√≥n no est√° finalizada por defecto
        )
        
        cur.execute(query, values)
        conn.commit()
        
        cur.close()
        conn.close()
        
        print("‚úÖ Interacci√≥n guardada en la base de datos")
    except Exception as e:
        print(f"‚ùå Error al guardar en la BD: {e}")


# Configurar el prompt personalizado  3
prompt_template_bryan = PromptTemplate(
    input_variables=["historial", "entrada"],
    template="""
    Eres un asistente virtual de ATOM dise√±ado para interactuar con prospectos a trav√©s de voz.
    Tu objetivo es:
    
    1. Comprender la intenci√≥n del usuario (preguntar por un producto, solicitar informaci√≥n, expresar dudas, etc.).
    2. Extraer informaci√≥n clave de la conversaci√≥n:
        - Nombre del usuario (si lo menciona).
        - Empresa o negocio (si lo menciona).
        - Necesidad espec√≠fica o problema que busca resolver.
        - Presupuesto estimado (si lo menciona).
    3. Responder de manera clara y √∫til, solo en espa√±ol. No inventes respuestas si no tienes suficiente informaci√≥n.

    Historial de la conversaci√≥n:
    {historial}

    Entrada del usuario:
    {entrada}


    Basado en esta entrada, responde EXCLUSIVAMENTE con un JSON bien formado con el siguiente esquema:
    {{
        "intencion": "<intenci√≥n detectada>",
        "nombre": "<nombre del usuario si lo menciona, o null>",
        "empresa": "<empresa del usuario si lo menciona, o null>",
        "necesidad": "<resumen de la necesidad del usuario>",
        "presupuesto": "<presupuesto si lo menciona, o null>",
        "respuesta": "<tu respuesta en espa√±ol>"
    }}

    Si alg√∫n dato no se menciona, usa `null` en su lugar.
    """
)


# Configurar el modelo de lenguaje y la memoria de la conversaci√≥n
#llm_ollama = Ollama(model="tinyllama", temperature=0.2)
llm_ollama = Ollama(model="mistral", temperature=0.2)

memory = ConversationBufferMemory(memory_key="historial")  # Memoria para mantener el contexto

conversacion = ConversationChain(llm=llm_ollama, 
                                 memory=memory,
                                 prompt=prompt_template_bryan,
                                 input_key="entrada"  # Asegura que la entrada del usuario se pase correctamente
                                 )


# Interacci√≥n en tiempo real
print("Bienvenido al Agente de Voz de ATOM. ¬øEn qu√© puedo ayudarte hoy?")
texto_a_voz("Bienvenido al Agente de Voz de ATOM. ¬øEn qu√© puedo ayudarte hoy?")


# OPCION 3 DE INTERACCION
while True:
    # 1. Capturar audio
    texto_usuario = capturar_audio()
    
    # 2. Salir si el usuario lo indica
    if texto_usuario and texto_usuario.lower() in ("salir", "exit"):
        texto_a_voz("Finalizando conversaci√≥n...")
        break
    
    # 3. Procesar interacci√≥n
    if texto_usuario:
        respuesta_llm = conversacion.invoke({"entrada": texto_usuario})["response"]
        #respuesta_parsed = parse_respuesta(conversacion.invoke({"entrada": texto_usuario})["response"])

        # Parsear la respuesta del LLM
        respuesta_parseada = parse_respuesta(respuesta_llm)
        
        # 5. Guardar TODOS los campos relevantes
        # Guardar en DB (versi√≥n robusta)
        guardar_interaccion_bd(texto_usuario, respuesta_parseada)
        
        # 6. Responder por voz
        #texto_a_voz(respuesta_parsed["respuesta"])
        texto_a_voz(respuesta_parseada.get("respuesta", "No entend√≠"))
        

